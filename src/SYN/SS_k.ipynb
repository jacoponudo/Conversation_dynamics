{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"root='/kaggle/working/'\nimport sys\n!git clone https://github.com/nudojacopo/thesis.git\nmodule_path = root+'thesis/src/SYN/SYN_package'\nsys.path.append(module_path)\nsys.path.append(module_path)\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom scipy import stats\nimport random\nfrom scipy.stats import chi2\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.gofplots import qqplot\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\n!pip install powerlaw\nfrom functions import *\nfrom estimate_parameters import *\nimport json\nfrom scipy import stats\nimport random\nfrom scipy.stats import chi2\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.gofplots import qqplot\nimport powerlaw\nimport warnings\n!pip install gdown\nimport gdown\n\nurl='https://drive.google.com/uc?id=1LUaN2XL3o9TIggKTxcNkmIGSdBx01Hqo'\noutput='facebook.csv'\ngdown.download(url,output,quiet=False)\n\nurl='https://drive.google.com/uc?id=1Dq5Z8KjEhbiUNTd8vgxX0ZK6aP_a7h4I'\noutput='voat.csv'\ngdown.download(url,output,quiet=False)\n\nurl='https://drive.google.com/uc?id=1jXcIGv2zoTZeuj8W2EPXyhQLOaiRU2Tn'\noutput='gab.csv'\ngdown.download(url,output,quiet=False)\n\nurl='https://drive.google.com/uc?id=1qCPKDWjl9CxaRf8EJK5oFGvwae0xC9-q'\noutput='reddit.csv'\ngdown.download(url,output,quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T20:26:55.263096Z","iopub.execute_input":"2024-09-05T20:26:55.263478Z","iopub.status.idle":"2024-09-05T20:27:52.216269Z","shell.execute_reply.started":"2024-09-05T20:26:55.263438Z","shell.execute_reply":"2024-09-05T20:27:52.215011Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"fatal: destination path 'thesis' already exists and is not an empty directory.\nRequirement already satisfied: powerlaw in /opt/conda/lib/python3.10/site-packages (1.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from powerlaw) (1.14.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from powerlaw) (1.26.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from powerlaw) (3.7.5)\nRequirement already satisfied: mpmath in /opt/conda/lib/python3.10/site-packages (from powerlaw) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->powerlaw) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->powerlaw) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->powerlaw) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->powerlaw) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->powerlaw) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->powerlaw) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->powerlaw) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->powerlaw) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->powerlaw) (1.16.0)\nRequirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.7.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1LUaN2XL3o9TIggKTxcNkmIGSdBx01Hqo\nFrom (redirected): https://drive.google.com/uc?id=1LUaN2XL3o9TIggKTxcNkmIGSdBx01Hqo&confirm=t&uuid=4098448a-b274-4eaf-a201-00a4a5dec670\nTo: /kaggle/working/facebook.csv\n100%|██████████| 1.17G/1.17G [00:03<00:00, 311MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1Dq5Z8KjEhbiUNTd8vgxX0ZK6aP_a7h4I\nFrom (redirected): https://drive.google.com/uc?id=1Dq5Z8KjEhbiUNTd8vgxX0ZK6aP_a7h4I&confirm=t&uuid=20c40753-b5f3-41eb-a19d-6f440496a20e\nTo: /kaggle/working/voat.csv\n100%|██████████| 112M/112M [00:00<00:00, 228MB/s] \nDownloading...\nFrom (original): https://drive.google.com/uc?id=1jXcIGv2zoTZeuj8W2EPXyhQLOaiRU2Tn\nFrom (redirected): https://drive.google.com/uc?id=1jXcIGv2zoTZeuj8W2EPXyhQLOaiRU2Tn&confirm=t&uuid=bf887692-0f28-419a-b142-b5d907745a46\nTo: /kaggle/working/gab.csv\n100%|██████████| 384M/384M [00:02<00:00, 180MB/s]  \nDownloading...\nFrom (original): https://drive.google.com/uc?id=1qCPKDWjl9CxaRf8EJK5oFGvwae0xC9-q\nFrom (redirected): https://drive.google.com/uc?id=1qCPKDWjl9CxaRf8EJK5oFGvwae0xC9-q&confirm=t&uuid=bf193ac3-a0c1-43ba-98c4-d59f3523cbeb\nTo: /kaggle/working/reddit.csv\n100%|██████████| 209M/209M [00:03<00:00, 53.2MB/s] \n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'reddit.csv'"},"metadata":{}}]},{"cell_type":"code","source":"fb=pd.read_csv('/kaggle/working/facebook.csv')\nrd=pd.read_csv('/kaggle/working/reddit.csv')\nvo=pd.read_csv('/kaggle/working/voat.csv')\ngb=pd.read_csv('/kaggle/working/gab.csv')\n\nh=100","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-05T20:27:52.218933Z","iopub.execute_input":"2024-09-05T20:27:52.219344Z","iopub.status.idle":"2024-09-05T20:28:34.203758Z","shell.execute_reply.started":"2024-09-05T20:27:52.219301Z","shell.execute_reply":"2024-09-05T20:28:34.202660Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"fb=filter_first_h(fb,h)\n\ngb=filter_first_h(gb,h)\n\nrd=filter_first_h(rd,h)\n\nvo=filter_first_h(vo,h)\n\nnames = ['gb','rd','fb','vo']\ndatas = [gb,rd,fb,vo]\n\nparams_dict = process_social_platform(names, datas)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T20:28:34.205200Z","iopub.execute_input":"2024-09-05T20:28:34.205718Z","iopub.status.idle":"2024-09-05T20:32:20.198262Z","shell.execute_reply.started":"2024-09-05T20:28:34.205647Z","shell.execute_reply":"2024-09-05T20:32:20.196563Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 4/4 [03:43<00:00, 55.77s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"time_intervals = np.arange(0, 1, 0.02)\nn=5000\n\nall_dfs = []\nfor i, df in enumerate(datas):\n    social = names[i]\n    parameters = params_dict[social]\n\n    simulated_t, observed_t = simulate_data(df, parameters, activate_tqdm=True, num_threads=n)# peensaree a come limitar i valori dell funzionee IAT senza crear break infiniti\n    globals()[f\"{social}s_M1\"] = simulated_t\n    globals()[f\"{social}o_M1\"] = observed_t\n    df_simulated = pd.DataFrame(simulated_t, columns=[f\"{social}s_M1_col{i}\" for i in range(simulated_t.shape[1])])\n    df_observed = pd.DataFrame(observed_t, columns=[f\"{social}o_M1_col{i}\" for i in range(observed_t.shape[1])])\n\n    df_simulated.to_csv(f\"{social}s_M1.csv\", index=False)\n    df_observed.to_csv(f\"{social}o_M1.csv\", index=False)\n\n    simulated_t_ECDF = calculate_ECDF(simulated_t, time_intervals)\n    simulated_t_ECDF['Platform'] = social\n    simulated_t_ECDF['Style'] = 'Simulated'\n\n    observed_t_ECDF = calculate_ECDF(observed_t, time_intervals)\n    observed_t_ECDF['Platform'] = social\n    observed_t_ECDF['Style'] = 'Observed'\n\n    df_platform = pd.concat([simulated_t_ECDF, observed_t_ECDF], ignore_index=True)\n    all_dfs.append(df_platform)\n\ndf_all_M1 = pd.concat(all_dfs, ignore_index=True)\ndf_all_M1['Time Grid Value']=df_all_M1['Time Grid Value']*100","metadata":{"execution":{"iopub.status.busy":"2024-09-05T22:36:41.139261Z","iopub.execute_input":"2024-09-05T22:36:41.139793Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 5000/5000 [00:22<00:00, 224.97it/s]\nProcessing DataFrame: 100%|██████████| 5000/5000 [03:34<00:00, 23.27it/s]\nProcessing DataFrame: 100%|██████████| 5000/5000 [03:31<00:00, 23.62it/s]\n 30%|███       | 1510/5000 [02:41<06:13,  9.35it/s]","output_type":"stream"}]},{"cell_type":"markdown","source":"Plain plot","metadata":{}},{"cell_type":"code","source":"df_all_M1['Time Grid Value']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Assuming df_all_M1 is your DataFrame\n# df_all_M1 = pd.read_csv('your_data.csv')\n\n# Sort the DataFrame by 'Style'\ndf_all = df_all_M1.sort_values(by='Style')\ndf_all_M1['Time Grid Value']=df_all_M1['Time Grid Value']*100\n# Define specific colors for each platform\ncolors = {\n    'Reddit': '#FF5700',\n    'Voat': '#800080',\n    'Facebook': '#3b5998',\n    'Gab': '#00c853'\n}\n\ndictionary= {\n    'rd': 'Reddit',\n    'vo': 'Voat',\n    'fb': 'Facebook',\n    'gb': 'Gab'\n}\ndf_all_M1['Platform'] = df_all_M1['Platform'].replace(dictionary)\n\n\n# Plot comment arrival dynamic\nplt.figure(figsize=(12, 8))\ndf_all_M1['Platform']\nsns.lineplot(data=df_all_M1, x='Time Grid Value', y='Share', hue='Platform', style='Style',\n             err_style='band',errorbar=('ci', 99), palette=colors)\nplt.ylabel('Quantile', fontsize=16)\nplt.xlabel('Time (hours)', fontsize=16)\nplt.grid(False)\n\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With Confidence interval","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Supponendo che df_all_M1 sia il tuo DataFrame\n# df_all_M1 = pd.read_csv('your_data.csv')\n\n# Ordinare il DataFrame per 'Style'\ndf_all = df_all_M1.sort_values(by='Style')\n\n# Definire colori specifici per ogni piattaforma\ncolors = {\n    'Reddit': '#FF5700',\n    'Voat': '#800080',\n    'Facebook': '#3b5998',\n    'Gab': '#00c853'\n}\n\ndictionary = {\n    'rd': 'Reddit',\n    'vo': 'Voat',\n    'fb': 'Facebook',\n    'gb': 'Gab'\n}\ndf_all_M1['Platform'] = df_all_M1['Platform'].replace(dictionary)\n\n# Funzione per calcolare i percentili\ndef calculate_percentiles(df):\n    return df.groupby(['Platform', 'Style', 'Time Grid Value']).agg(\n        p20=('Share', lambda x: np.percentile(x, 40)),\n        p80=('Share', lambda x: np.percentile(x, 60)),\n        mean=('Share', 'median')\n    ).reset_index()\n\n# Calcolare i percentili e la media\ngrouped = calculate_percentiles(df_all_M1)\n\n# Ottenere stili e piattaforme unici\nstyles = df_all_M1['Style'].unique()\nplatforms = df_all_M1['Platform'].unique()\n\n# Plot dei percentili e della media\nplt.figure(figsize=(12, 8))\n\nfor platform in platforms:\n    platform_data = grouped[grouped['Platform'] == platform]\n    for style in styles:\n        style_data = platform_data[platform_data['Style'] == style]\n        linestyle = '--' if style == 'Simulated' else '-'\n        plt.plot(style_data['Time Grid Value'], style_data['mean'], \n                 label=f'{platform} - {style} (Mean)', \n                 color=colors.get(platform, 'black'), linestyle=linestyle)\n        \n        # Aggiungere poligoni tra i percentili\n        plt.fill_between(style_data['Time Grid Value'], \n                         style_data['p20'], \n                         style_data['p80'], \n                         color=colors.get(platform, 'black'), \n                         alpha=0.3)\n\nplt.ylabel('Quantile', fontsize=16)\nplt.xlabel('Time (hours)', fontsize=16)\nplt.grid(True)\nplt.legend(title='Platform - Style')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming df_all_M1 is your DataFrame containing Simulate and Observed data\n# Sort the DataFrame by 'Style' (if necessary)\ndf_all = df_all_M1.sort_values(by='Style')\n\n# Define a dictionary to map abbreviations to full platform names\ndictionary = {\n    'rd': 'Reddit',\n    'vo': 'Voat',\n    'fb': 'Facebook',\n    'gb': 'Gab'\n}\ndf_all_M1['Platform'] = df_all_M1['Platform'].replace(dictionary)\n\n# Assuming 'Simulate' and 'Observed' columns are already calculated or available in df_all_M1\n\n# Loop through each platform to perform KS test and plot the results\nplatforms = df_all_M1['Platform'].unique()\n\nfor platform in platforms:\n    # Extract Simulate and Observed data for the current platform\n    data_simulate = df_all_M1[(df_all_M1['Platform'] == platform) & (df_all_M1['Style']=='Simulated')]['Share']\n    data_observed = df_all_M1[(df_all_M1['Platform'] == platform) & (df_all_M1['Style']=='Observed')]['Share']\n    \n    # Perform KS test\n    ks_statistic, p_value = stats.ks_2samp(data_simulate, data_observed)\n    \n    # Print KS test results\n    print(f\"KS Test for {platform}: Statistic={ks_statistic:.4f}, p-value={p_value:.4f}\")\n    \n    # Plot Simulate vs Observed for the current platform\n    plt.figure(figsize=(10, 6))\n    sns.kdeplot(data_simulate, label='Simulated', color='blue', shade=True)\n    sns.kdeplot(data_observed, label='Observed', color='orange', shade=True)\n    plt.title(f'Simulate vs Observed for {platform}')\n    plt.xlabel('Value')\n    plt.ylabel('Density')\n    plt.legend()\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.spatial.distance import jensenshannon\n\n# Supponiamo che df_all_M1 contenga tutte le piattaforme e stili.\n# A questo punto avrai due gruppi di dati: observed e simulated.\n\n# Funzione per calcolare il mean share e la distanza di Jensen-Shannon\ndef compute_distance(df, platform_observed, platform_simulated):\n    # Calcolare il mean share per Observed e Simulated\n    observed_mean_share_by_time_grid = df[(df['Platform'] == platform_observed) & (df['Style'] == 'Observed')].groupby('Time Grid Value')['Share'].mean().diff().dropna()\n    simulated_mean_share_by_time_grid = df[(df['Platform'] == platform_simulated) & (df['Style'] == 'Simulated')].groupby('Time Grid Value')['Share'].mean().diff().dropna()\n    \n    # Arrotondamento\n    observed_mean_share_by_time_grid = observed_mean_share_by_time_grid.round(5)\n    simulated_mean_share_by_time_grid = simulated_mean_share_by_time_grid.round(5)\n    \n    # Normalizzazione\n    observed_mean_share_by_time_grid = observed_mean_share_by_time_grid / sum(observed_mean_share_by_time_grid)\n    simulated_mean_share_by_time_grid = simulated_mean_share_by_time_grid / sum(simulated_mean_share_by_time_grid)\n    \n    # Calcolo della distanza di Jensen-Shannon\n    distance = jensenshannon(simulated_mean_share_by_time_grid, observed_mean_share_by_time_grid)\n    \n    return distance\n\n# Elenco delle piattaforme\nplatforms = df_all_M1['Platform'].unique()\n\n# Creare una tabella a doppia entrata\ndistance_matrix = pd.DataFrame(index=platforms, columns=platforms)\n\n# Riempire la tabella con le distanze\nfor platform_observed in platforms:\n    for platform_simulated in platforms:\n            distance_matrix.loc[platform_observed, platform_simulated] = compute_distance(df_all_M1, platform_observed, platform_simulated)\n\n# Mostrare la tabella a doppia entrata\nprint(distance_matrix)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Converti i valori nella matrice a float\ndistance_matrix = distance_matrix.astype(float)\n\n# Definisci una nuova palette graduale di viola\nnew_palette = sns.color_palette(\"YlOrRd\", as_cmap=True)\n\n# Crea una heatmap della matrice delle distanze\nplt.figure(figsize=(10, 8))\nsns.heatmap(distance_matrix, annot=True, cmap=new_palette, fmt=\".3f\", linewidths=.5)\nplt.title(\"Jensen-Shannon Distance Matrix between Platforms\")\nplt.xlabel(\"Simulated\")\nplt.ylabel(\"Observed\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm  # tqdm for progress bar\n\n# Assuming rd, fb, vo, yt are your DataFrames\n\n# Add 'platform' column to each DataFrame\nrdo_M1['platform'] = 'Reddit'\nvoo_M1['platform'] = 'Voat'\nfbo_M1['platform'] = 'Facebook'\ngbo_M1['platform'] = 'Gab'\n# Combine all DataFrames into a single DataFrame\nall_data = []\n\n# Process each dataset individually\nfor df in tqdm([rdo_M1,  voo_M1,fbo_M1,gbo_M1]):#yto\n    df['number_of_comments'] = df.groupby('post_id')['post_id'].transform('count')\n    df['sequential_position'] = df.groupby('post_id')['temporal_distance_birth_base_100h'].rank(method='first')\n\n    # Determine the number of bins\n    num_bins = 20\n\n    # Calculate the bin of position\n    df['bin_of_position'] = ((df['sequential_position'] - 1) / df['number_of_comments'] * num_bins).astype(int) + 1\n    df['first_comment']=df['sequential_number_of_comment_by_user_in_thread']==1\n    # Group by 'bin_of_position', 'post_id', and calculate unique users per post\n    df['first_comment'] = df.groupby(['bin_of_position', 'post_id'])['first_comment'].transform('mean')\n    all_data.append(df)\nall_data = pd.concat(all_data, ignore_index=True)\n# Aggregate data across all datasets\nagg_activity_obs = all_data.groupby(['platform', 'bin_of_position', 'post_id'])['first_comment'].mean().reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm  # tqdm for progress bar\n\n# Assuming rd, fb, vo, yt are your DataFrames\n\n# Add 'platform' column to each DataFrame\nrds_M1['platform'] = 'Reddit'\nvos_M1['platform'] = 'Voat'\nfbs_M1['platform'] = 'Facebook'\ngbs_M1['platform'] = 'Gab'\n# Combine all DataFrames into a single DataFrame\nall_data = []\n\n# Process each dataset individually\nfor df in tqdm([rds_M1,  vos_M1,fbs_M1,gbs_M1]):#yto\n    df['number_of_comments'] = df.groupby('post_id')['post_id'].transform('count')\n    df['sequential_position'] = df.groupby('post_id')['temporal_distance_birth_base_100h'].rank(method='first')\n\n    # Determine the number of bins\n    num_bins = 20\n\n    # Calculate the bin of position\n    df['bin_of_position'] = ((df['sequential_position'] - 1) / df['number_of_comments'] * num_bins).astype(int) + 1\n\n    df['first_comment']=df['sequential_number_of_comment_by_user_in_thread']==1\n    # Group by 'bin_of_position', 'post_id', and calculate unique users per post\n    df['first_comment'] = df.groupby(['bin_of_position', 'post_id'])['first_comment'].transform('mean')\n    all_data.append(df)\nall_data = pd.concat(all_data, ignore_index=True)\n# Aggregate data across all datasets\nagg_activity_sim_M1 = all_data.groupby(['platform', 'bin_of_position', 'post_id'])['first_comment'].mean().reset_index()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define custom colors\ncolors = {\n    'Reddit': '#FF5700',\n    'Voat': '#800080',\n    'Facebook': '#3b5998',\n    'Gab': '#00c853'\n}\n\n# Assuming you have already defined agg_activity_sim_M1 and agg_activity_obs dataframes\n\n# Setting up the figure with subplots\nplt.figure(figsize=(24, 8))  # Adjust the figure size as needed\n\n# Convert bin_of_position to integer\nagg_activity_sim_M1['bin_of_position'] = agg_activity_sim_M1['bin_of_position'].astype(int)\nagg_activity_obs['bin_of_position'] = agg_activity_obs['bin_of_position'].astype(int)\n\n# Subplot for the first plot (agg_activity_sim_M1)\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, first plot\nsns.lineplot(\n    data=agg_activity_sim_M1,\n    x='bin_of_position',\n    y='first_comment',\n    hue='platform',  # Different line for each platform\n    estimator='mean',  # Aggregation preference\n    errorbar=('ci', 99),  # 80% confidence interval\n    linewidth=3,\n    palette=colors  # Use custom colors defined in the dictionary\n)\nplt.title('Simulated')\nplt.ylabel('Average Unique Users per Post')\nplt.xlabel('Bin of Position')\nplt.grid(False)\n\n# Set y-axis limits\nplt.ylim(0.2, 1)\n\n# Set x-axis ticks as integers\nplt.xticks(agg_activity_sim_M1['bin_of_position'].unique())\n\n# Manually setting the line style for one of the platforms\nlines = plt.gca().get_lines()\nfor line in lines:\n    line.set_linestyle('--')\n\n# Subplot for the second plot (agg_activity_obs)\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, second plot\nsns.lineplot(\n    data=agg_activity_obs,\n    x='bin_of_position',\n    y='first_comment',\n    hue='platform',  # Different line for each platform\n    estimator='mean',  # Aggregation preference\n    errorbar=('ci', 99),  # 80% confidence interval\n    linewidth=3,\n    palette=colors  # Use custom colors defined in the dictionary\n)\nplt.title('Observed')\nplt.ylabel('Share of first comment')\nplt.xlabel('Bin of Position')\nplt.grid(False)\n\n# Set y-axis limits\nplt.ylim(0.2, 1)\n\n# Set x-axis ticks as integers\nplt.xticks(agg_activity_obs['bin_of_position'].unique())\n\n# Adjust layout and show the plot\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom scipy import stats\n\n# Assuming df_all_M1 is your DataFrame containing the necessary data\n\n# Define the platforms and styles\nplatforms = ['Reddit', 'Voat', 'Gab', 'Facebook']\nstyles = ['Observed', 'Simulated']\n\n# Initialize an empty dictionary to store KS test results\nks_results = {}\n\n# Loop through each platform\nfor platform in platforms:\n    # Initialize a dictionary for the current platform\n    ks_results[platform] = {}\n    \n    # Loop through each style\n    for style in styles:\n        # Extract the data for the current platform and style\n        data = df_all_M1[(df_all_M1['Style'] == style) & (df_all_M1['Platform'] == platform)]['Share'].sample(11000)\n        \n        # Store the data in the dictionary\n        ks_results[platform][style] = data\n        \n# Initialize an empty matrix to store KS test results\nks_matrix = pd.DataFrame(index=platforms, columns=platforms)\n\n# Loop through combinations of platforms\nfor platform1 in platforms:\n    for platform2 in platforms:\n        # Perform KS test between platform1 and platform2\n        ks_statistic, p_value = stats.ks_2samp(ks_results[platform1]['Observed'], ks_results[platform2]['Simulated'])\n        \n        # Store the p-value in the ks_matrix\n        ks_matrix.loc[platform1, platform2] = p_value\n\n# Display the KS test matrix\nprint(\"KS Test p-values Matrix:\")\nprint(ks_matrix)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define custom colors\ncolors = {\n    'Reddit': '#FF5700',\n    'Voat': '#800080',\n    'Facebook': '#3b5998',\n    'Gab': '#00c853'\n}\n\n# Assuming you have already defined agg_activity_sim_M1 and agg_activity_obs dataframes\n\n# Convert bin_of_position to integer\nagg_activity_sim_M1['bin_of_position'] = agg_activity_sim_M1['bin_of_position'].astype(int)\nagg_activity_obs['bin_of_position'] = agg_activity_obs['bin_of_position'].astype(int)\n\n# Fit linear regression models\ndef fit_linear_model(data, platform):\n    X = sm.add_constant(data['bin_of_position'])\n    y = data['first_comment']\n    model = sm.OLS(y, X).fit()\n    return model.params[1]  # Return the slope\n\nplatforms = ['Reddit', 'Voat', 'Facebook', 'Gab']\n\n# Calculate slopes for each platform in both datasets\nslopes_sim = {platform: fit_linear_model(agg_activity_sim_M1[agg_activity_sim_M1['platform'] == platform], platform) for platform in platforms}\nslopes_obs = {platform: fit_linear_model(agg_activity_obs[agg_activity_obs['platform'] == platform], platform) for platform in platforms}\n\n# Calculate the differences\ndifferences = {platform: slopes_obs[platform] - slopes_sim[platform] for platform in platforms}\n\n# Create a DataFrame to present the results\nresults_df = pd.DataFrame({\n    'Observed Slope': slopes_obs,\n    'Simulated Slope': slopes_sim,\n    'Difference': differences\n})\n\nprint(results_df)\n\n# Plotting\nplt.figure(figsize=(24, 8))  # Adjust the figure size as needed\n\n# Subplot for the simulated data\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, first plot\nsns.lineplot(\n    data=agg_activity_sim_M1,\n    x='bin_of_position',\n    y='first_comment',\n    hue='platform',  # Different line for each platform\n    estimator='mean',  # Aggregation preference\n    errorbar=('ci', 99),  # 80% confidence interval\n    linewidth=3,\n    palette=colors  # Use custom colors defined in the dictionary\n)\nplt.title('Simulated')\nplt.ylabel('Average Unique Users per Post')\nplt.xlabel('Bin of Position')\nplt.grid(False)\n\n# Set y-axis limits\nplt.ylim(0.2, 1)\n\n# Set x-axis ticks as integers\nplt.xticks(agg_activity_sim_M1['bin_of_position'].unique())\n\n# Subplot for the observed data\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, second plot\nsns.lineplot(\n    data=agg_activity_obs,\n    x='bin_of_position',\n    y='first_comment',\n    hue='platform',  # Different line for each platform\n    estimator='mean',  # Aggregation preference\n    errorbar=('ci', 99),  # 80% confidence interval\n    linewidth=3,\n    palette=colors  # Use custom colors defined in the dictionary\n)\nplt.title('Observed')\nplt.ylabel('Share of first comment')\nplt.xlabel('Bin of Position')\nplt.grid(False)\n\n# Set y-axis limits\nplt.ylim(0.2, 1)\n\n# Set x-axis ticks as integers\nplt.xticks(agg_activity_obs['bin_of_position'].unique())\n\n# Adjust layout and show the plot\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}